##############################################################################
#
#   MRC FGU CGAT
#
#   $Id$
#
#   Copyright (C) 2009 Andreas Heger
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################
"""===========================
Pipeline template
===========================

:Author: Andreas Heger
:Release: $Id$
:Date: |today|
:Tags: Python

.. Replace the documentation below with your own description of the
   pipeline's purpose

Overview
========

This pipeline computes the word frequencies in the configuration
files :file:``pipeline.ini` and :file:`conf.py`.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_gwasenrichment.py config

Input files
-----------

None required except the pipeline configuration files.

Requirements
------------

The pipeline requires the results from
:doc:`pipeline_annotations`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

On top of the default CGAT setup, the pipeline requires the following
software to be in the path:

.. Add any additional external requirements such as 3rd party software
   or R modules below:

Requirements:

* samtools >= 1.1

Pipeline output
===============

.. Describe output files of the pipeline here

Glossary
========

.. glossary::


Code
====

"""
from ruffus import *
from ruffus.combinatorics import *

import sys
import os
import sqlite3
import CGAT.Experiment as E
import CGATPipelines.Pipeline as P

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])

# add configuration values from associated pipelines
#
# 1. pipeline_annotations: any parameters will be added with the
#    prefix "annotations_". The interface will be updated with
#    "annotations_dir" to point to the absolute path names.
PARAMS.update(P.peekParameters(
    PARAMS["annotations_dir"],
    "pipeline_annotations.py",
    on_error_raise=__name__ == "__main__",
    prefix="annotations_",
    update_interface=True))


# if necessary, update the PARAMS dictionary in any modules file.
# e.g.:
#
# import CGATPipelines.PipelineGeneset as PipelineGeneset
# PipelineGeneset.PARAMS = PARAMS
#
# Note that this is a hack and deprecated, better pass all
# parameters that are needed by a function explicitely.

# -----------------------------------------------
# Utility functions
def connect():
    '''utility function to connect to database.

    Use this method to connect to the pipeline database.
    Additional databases can be attached here as well.

    Returns an sqlite3 database handle.
    '''

    dbh = sqlite3.connect(PARAMS["database"])
    statement = '''ATTACH DATABASE '%s' as annotations''' % (
        PARAMS["annotations_database"])
    cc = dbh.cursor()
    cc.execute(statement)
    cc.close()

    return dbh


# ---------------------------------------------------#
# ---------------------------------------------------#
# ---------------------------------------------------#
# Get the relevant annotations first for enrichments
# Merge enrichments into a single file if necessary
@follows(mkdir("bed.dir"))
@collate("%s/*.bed.gz" % PARAMS['bed_files'],
         regex("%s/(.+)-(.+).bed.gz" % PARAMS['bed_files']),
         r"bed.dir/\1.bed.gz")
def mergeBedAnnotations(infiles, outfile):
    '''
    Merge together multiple BED format annotations
    into a single file.  Give the annotation type,
    assumed to be element 2 of the file name,
    as the annotation name in the output file.
    '''

    all_files = ",".join(infiles)

    job_memory = "1G"

    statement = '''
    python /ifs/devel/projects/proj045/enrichment_pipeline/merge_beds.py
    --regex-filename="-(.+).bed.gz"
    --log=%(outfile)s.log
    %(all_files)s
    | gzip > %(outfile)s
    '''

    P.run()

# assign SNPs to linkage/haplotype blocks in bed format

@follows(mkdir("haplotypes.dir"))
@transform("%s/*.blocks.det" % PARAMS['snpset_haplotypes'],
           regex("%s/(.+).blocks.det" % PARAMS['snpset_haplotypes']),
           r"haplotypes.dir/\1.bed.gz")
def convertHaplotypes2Bed(infile, outfile):
    '''
    Convert Plink1.9 haplotype blocks to bed interval
    format.
    '''

    job_memory = "1G"

    statement = '''
    python /ifs/devel/projects/proj045/enrichment_pipeline/haplotypes2bed.py
    --header
    --contig-column=1
    --start-column=2
    --end-column=3
    --snp-column=6
    --log=%(outfile)s.log
    <( cat %(infile)s | tr -s ' ' '\\t' | sed 's/^[[:space:]]*//g' | sed 's/*[[:space:]]$//g')
    | gzip > %(outfile)s
    '''

    P.run()

@follows(convertHaplotypes2Bed)
@collate(convertHaplotypes2Bed,
         regex("haplotypes.dir/(.+).bed.gz"),
         r"haplotypes.dir/WholeGenome.bed.gz")
def mergeHaplotypeBeds(infiles, outfile):
    '''
    Merge individual chromosome haplotype
    bed files
    '''

    infiles = " ".join(infiles)

    statement = '''
    zcat %(infiles)s | gzip >> %(outfile)s
    '''

    P.run()

@follows(mergeHaplotypeBeds,
         mkdir("snpsets.dir"))
@transform("%s/*.tsv" % PARAMS['snpset_dir'],
           regex("(.+)/(.+).tsv"),
           add_inputs(mergeHaplotypeBeds),
           r"snpsets.dir/\2.snpset.gz")
def convertSet2Block(infiles, outfile):
    '''
    Convert list of SNP IDs into
    interval haplotype or linkage blocks
    '''

    snp_file = infiles[0]
    bed_file = infiles[1]

    job_memory = "1G"

    statement = '''
    python /ifs/devel/projects/proj045/enrichment_pipeline/snps2bed.py
    --ld-source=plink
    --ld-blocks=%(bed_file)s
    --log=%(outfile)s.log
    %(snp_file)s
    | gzip > %(outfile)s
    '''

    P.run()

# ---------------------------------------------------#
# ---------------------------------------------------#
# ---------------------------------------------------#
# Perform enrichment analysis of SNPset and annotation
# overlap with GAT

@follows(convertSet2Block,
         mergeBedAnnotations,
         mkdir("gat.dir"))
@product(convertSet2Block,
         formatter("(.snpset.gz)$"),
         mergeBedAnnotations,
         formatter("(.bed.gz$)"),
         "gat.dir/"
         "{basename[0][0]}_vs_"
         "{basename[1][0]}.gat")
def genomicAsssociationTest(infiles, outfile):
    '''
    Use GAT to test for enrichment of overlap
    between SNP sets and annotations of interest.

    GAT must be in the $PATH variable

    '''

    job_memory = "3G"
    job_threads = 2
    snpset = infiles[0]
    annotations = infiles[1]

    statement = '''
    gat-run.py
    --segments=%(snpset)s
    --annotations=%(annotations)s
    --workspace=%(gat_mappability)s
    --workspace=%(gat_ungapped)s
    --ignore-segment-tracks
    --num-samples=%(gat_samples)s
    --num-threads=%(job_threads)s
    --log=%(outfile)s.log
    > %(outfile)s
    '''

    P.run()


# ---------------------------------------------------
# Generic pipeline tasks
@follows(convertSet2Block,
         mergeBedAnnotations)
def process_samples():
    pass


@follows()
def full():
    pass


@follows(mkdir("report"))
def build_report():
    '''build report from scratch.

    Any existing report will be overwritten.
    '''

    E.info("starting report build process from scratch")
    P.run_report(clean=True)


@follows(mkdir("report"))
def update_report():
    '''update report.

    This will update a report with any changes inside the report
    document or code. Note that updates to the data will not cause
    relevant sections to be updated. Use the cgatreport-clean utility
    first.
    '''

    E.info("updating report")
    P.run_report(clean=False)


@follows(update_report)
def publish_report():
    '''publish report in the CGAT downloads directory.'''

    E.info("publishing report")
    P.publish_report()

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
